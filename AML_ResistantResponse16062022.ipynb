{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AML_ResistantResponse16062022.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "private_outputs": true,
      "authorship_tag": "ABX9TyPSeXsg4QvQkiaWeD/FyeZw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hossein-Fallahi/AML-survival-analysis/blob/main/AML_ResistantResponse16062022.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-X3lA0IGUvn8"
      },
      "outputs": [],
      "source": [
        "# One of the challenges in curing cancer is using chemothrapy for treatment. However, not all patients benefite from all types of therapy. \n",
        "#Here, we rae trying to use ML to see which group of patient repond to what type of therpy. "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data and environment"
      ],
      "metadata": {
        "id": "rMWY-3rdQaQb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# First we need to get the required libraries for starting the project. Later we migth need more libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "VrdqJXCSZT18"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the data from your machine- You can modify the code to do this in googlecolab. \n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "df = pd.read_csv('aml-rppa.csv')\n",
        "\n",
        "# the data is in a dataframe. look at the head of the data\n",
        "df.head(7)"
      ],
      "metadata": {
        "id": "y30hwzK5Z5AA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data manipulation"
      ],
      "metadata": {
        "id": "MAKAGzAZQvwT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " #Lets look a bit dipper to the data- starting with the count of the number of rows and columns\n",
        "df.shape "
      ],
      "metadata": {
        "id": "w9NWWkllcg5n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Some coulmns contain un necessary information- drop all non essential columns for our analysis\n",
        "df.drop(df.columns[[0, 1, 2,6,7,14]], axis = 1, inplace = True)\n",
        "#note that eachtime the df is getting updated! probably i could do much better to drop all in one go!\n",
        "df.drop(df.columns[[0,1,2,4,5,6,7]], axis = 1, inplace = True)\n",
        "df.drop(df.columns[[0,1,2]], axis = 1, inplace = True)\n",
        "df.drop(df.columns[[0,1,2,3,4,5,6]], axis = 1, inplace = True)\n",
        "df.drop(df.columns[[1,3,5,6]], axis = 1, inplace = True)\n",
        "\n",
        "df"
      ],
      "metadata": {
        "id": "8LJ3c9Tq-EdZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#count of the number of empty values (e.g. NaN, NAN, na) in each column\n",
        "df.isna().sum()"
      ],
      "metadata": {
        "id": "Z87isT6Ldfz0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# drop the coulmns with empty values. \n",
        "df.drop(df.columns[[0]], axis = 1, inplace = True)\n",
        "df"
      ],
      "metadata": {
        "id": "O8Iye2QMK8MI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# OS migth not be useful here. drop this coulmn as well\n",
        "df.drop(df.columns[[0]], axis = 1, inplace = True)\n",
        "df"
      ],
      "metadata": {
        "id": "LODMT1e1LFMg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#drop the columns with all missing values- I did not drop the NA containg couumns as Response coulmn would be removed\n",
        "#df = df.dropna(axis=1)"
      ],
      "metadata": {
        "id": "gxHhQjEZetVM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#get the new coumnt of the data\n",
        "df.shape"
      ],
      "metadata": {
        "id": "tb5Nb9W2fAJa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#For the response coulmn, get the count of CR, Resistance or FAIL occurances\n",
        "df['Response'].value_counts()\n"
      ],
      "metadata": {
        "id": "HBKIfpnifG3p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# visualize the counts in a graph\n",
        "sns.countplot(df['Response'], label = 'count')"
      ],
      "metadata": {
        "id": "U_vZHaA-irar"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#look at the data type to see whcih coulmn need to be transformed (encoded)- \n",
        "df.dtypes"
      ],
      "metadata": {
        "id": "tU7yA773jN2w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#get the column index for \"response\"\n",
        "df.columns.get_loc(\"Response\")\n",
        "df.iloc[:,0].values"
      ],
      "metadata": {
        "id": "Uqa2azJGj4Xu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# encode the categorical datavalues\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "labelencoder_Y = LabelEncoder()\n",
        "df.iloc[:,0] = labelencoder_Y.fit_transform(df.iloc[:,0].values)\n",
        "df.iloc[:,0]\n",
        "#get ride of 0's as they are decoded for \"nan\" values\n",
        "df = df[df.Response != 0]\n"
      ],
      "metadata": {
        "id": "HN5X0F3SHaC1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "UzsWn0adOE3x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#get ride of CR's, which are coded as 3- The remaing are Fails or resistance\n",
        "df = df[df.Response != 3]\n",
        "df"
      ],
      "metadata": {
        "id": "v2a4_pRWOL9c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# creat a pair plot- not for all only the 5 first coulmns\n",
        "sns.pairplot(df.iloc[:,0:6], hue ='Response')"
      ],
      "metadata": {
        "id": "FxHoxRJaI3Tk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print the first 5 row of the new dataset\n",
        "df.head(5)"
      ],
      "metadata": {
        "id": "-ViPldoFN16-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#get the correlation of the coulmns\n",
        "df.iloc[:,0:12].corr()"
      ],
      "metadata": {
        "id": "qcAwNTLCOKnt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#visualize the correlation\n",
        "plt.figure(figsize=(10,10))\n",
        "sns.heatmap(df.iloc[:,0:12].corr(), annot=True, fmt ='.0%')"
      ],
      "metadata": {
        "id": "uyFFGYZIO-z0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# some additonal data manipulation- I migth do this a littel eralier\n",
        "df = df.replace(['NO'],'0.0')\n",
        "df = df.replace(['YES'],'1.0')\n",
        "#remove column with NaN values- \n",
        "df = df.dropna(axis=1)\n",
        "df\n"
      ],
      "metadata": {
        "id": "mmSpYY3bTAnM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Spliting data and modelling"
      ],
      "metadata": {
        "id": "lEah4hYQRRII"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Split the dataset into independent (X) and dependet (Y)\n",
        "X = df.iloc[:,1:].values\n",
        "Y = df.iloc[:,0].values\n",
        "\n",
        "#type(X) it is an array"
      ],
      "metadata": {
        "id": "E8-Usx_TPkyY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#split 75% training and test 25%\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X,Y ,test_size = 0.25, random_state = 0)"
      ],
      "metadata": {
        "id": "mUm7AUOkQiL7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Scale the data (Feature Scaling)\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.fit_transform(X_test)"
      ],
      "metadata": {
        "id": "v6AmfDpbR4CR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#creat a few models using a function- here we try 3 models\n",
        "def models (X_train, Y_train):\n",
        "\n",
        "  #logistic regression\n",
        "  from sklearn.linear_model import LogisticRegression\n",
        "  log = LogisticRegression(random_state =0)\n",
        "  log.fit(X_train, Y_train)\n",
        "\n",
        "  #Decision Tree\n",
        "  from sklearn.tree import DecisionTreeClassifier\n",
        "  tree = DecisionTreeClassifier(criterion = 'entropy', random_state=0)\n",
        "  tree.fit(X_train, Y_train)\n",
        "\n",
        "  #Random forest classifier\n",
        "  from sklearn.ensemble import RandomForestClassifier\n",
        "  forest = RandomForestClassifier(n_estimators = 10 , criterion= 'entropy', random_state = 0)\n",
        "  forest.fit(X_train, Y_train)\n",
        "\n",
        "  #print the model accuracy\n",
        "  print('[0]Logistic regression accuracy :', log.score(X_train, Y_train))\n",
        "  print('[1]Decision Tree accuracy :', tree.score(X_train, Y_train))\n",
        "  print('[2]Random Forest accuracy :', forest.score(X_train, Y_train))\n",
        "\n",
        "  return log, tree, forest"
      ],
      "metadata": {
        "id": "VL_h9T1hTYca"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#use the function to get the accuracy \n",
        "model = models (X_train, Y_train)"
      ],
      "metadata": {
        "id": "gf322sEEWGvC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#test the model on test data confusion matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "for i in range(len(model)):\n",
        "    print('Model ', i)\n",
        "    cm = confusion_matrix(Y_test, model[i].predict(X_test))\n",
        "\n",
        "    TP = cm[0][0]\n",
        "    TN = cm[1][1]\n",
        "    FN = cm[1][0]\n",
        "    FP = cm[0][1]\n",
        "\n",
        "    print(cm)\n",
        "    print('testing accuracy = ', (TP + TN)/ (TP + TN + FN + FP))\n",
        "    print()"
      ],
      "metadata": {
        "id": "NEkTXJ2Paqe9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#show anothoer way to get matrix for the accuracy\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "for i in range(len(model)):\n",
        "    print('Model ', i)\n",
        "    print(classification_report(Y_test, model[i].predict(X_test)))\n",
        "    print(accuracy_score(Y_test, model[i].predict(X_test)))\n",
        "    print()"
      ],
      "metadata": {
        "id": "ZzPq8bjRdWk0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#See how the model performed. e.g, preditcion of random forest model\n",
        "pred = model[2].predict(X_test)\n",
        "print(pred)\n",
        "print()\n",
        "print(Y_test)\n"
      ],
      "metadata": {
        "id": "UZUatY1Oe1zF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As you can see the model performance is not that great. Work on data sources to find better predictors with higher ranking values. "
      ],
      "metadata": {
        "id": "7AHI__oxDjK9"
      }
    }
  ]
}